# 3. System Architecture: Content Addressability, Schema-First, and Performance

## 3.1 Core Principles

### Pure Content Addressability
- Everything is content-addressed via 256-bit E entities (cidstore.E format with SHA-256)
- E entities have four 64-bit fields: high, high_mid, low_mid, low
- No distinction between data, metadata, or schemas—all are E entities
- Deterministic E generation through SHA-256 hashing
- Direct compatibility with cidstore for triple storage via ZMQ/msgpack data plane

### Schema-First Architecture
```markdown
# System architecture (overview)

This document summarizes the system-level architecture aligned to the proposed extraction and validation pipeline. It emphasizes modular services, content-addressed artifacts, provenance, and safe deployment via the Validation Layer.

High-level flow

flowchart LR
  Raw[Raw Messages] --> Pre[Preprocessor / Chunker]
  Pre --> Sym[Symbolic Extractor (real-time)]
  Sym -->|high-confidence| CIDIns[cidstore.insert(key, value)]
  Sym -->|ambiguous| Micro[Micro-LLM Fallback]
  Micro -->|candidate| CF[CandidateFactoid]
  CF --> Val[Validation Layer]
  Val -->|confirmed| CIDIns
  Val -->|rejected| Back[Backlog / Dreaming]
  Back --> Dream[Dreaming Batch (LLM + Coref)]
  Dream --> CIDIns

Core system components
- Preprocessor / Chunker: language detection, redaction, chunking, and chunk-level hashing.
- Symbolic Extractor: deterministic rules, dependency patterns, and NER for high-confidence auto-assertions.
- Micro-LLM Fallback: tiny transformer for ambiguous extractions; outputs CandidateFactoids (never auto-inserted).
- Validation Layer: bot services + human/community prompts, consensus rules, TTLs, and audit logs.
- Backlog / Dreaming: prioritized durable queue and batch LLM pipeline for reprocessing and predicate discovery.
- Predicate Registry: ontology service with predicate URIs, versions, aliases, deprecation and migration scripts.
- CID Mapper & Inserter: canonicalization, E entity generation (SHA-256, 256-bit with 4×64-bit parts), msgpack serialization with high/high_mid/low_mid/low fields, and optimized batch insertion into cidstore via ZMQ data plane using batch_insert() with adaptive batch sizing (32-1024 items) targeting >1M ops/sec throughput.
- Curation Console: human interfaces for moderators and curators to inspect factoids, votes, and to perform bulk actions.
- Monitoring & Governance: metrics, SLIs, drift detection, shadow testing, and alerting.

### Validation Layer (integrated proposal)

The Validation Layer mediates ambiguous candidate factoids generated by the Micro-LLM fallback and prevents noisy LLM output from being auto-inserted into the canonical graph. Key responsibilities (integrated from the proposed changes) include:

- Converting CandidateFactoid records into bot- or human-facing prompts (via personas such as Barkeep, Critic, Historian).
- Collecting ValidationEvent responses and applying a decision algorithm based on priority, TTL, responder type (author, moderator, community), and weighted consensus.
- On confirmation: build (subject: E, predicate: E, object: E) triples, serialize using msgpack format with 256-bit E entity fields (high, high_mid, low_mid, low), and call cidstore batch_insert via ZMQ with performance optimization (target <100μs P99 latency) to store compound keys for subject-predicate-object query patterns.
- On rejection/expiry: route the CandidateFactoid (or an associated BacklogItem) to the Dreaming pipeline for deeper batch LLM processing (coref + tripleizer) and predicate discovery.
- Record every validation step as meta-triples in cidstore with WAL-backed persistence and idempotent retry logic to enable a walkable provenance chain: triple -> factoid -> message -> validation events -> responders.

Decisioning highlights:

- Priority lanes for critical/high/normal/low factoids with distinct TTLs and routing (e.g., critical -> moderator lane, short TTL).
- Consensus rules (example): author confirmation results in fast confirmation; community confirmations (>=2 distinct confirmers) confirm unless explicitly rejected by the author; >=2 distinct rejects or explicit moderator rejection causes rejection; TTL expiry pushes to Dreaming.
- Conflict handling: when author and community disagree, mark triple modality (e.g., belief) and flag for moderator review.

The canonical specs reference the Validation Layer and its flows; this section consolidates the proposed behavioral and auditing details into the architecture-level documentation.

Deployment considerations
- Real-time services are horizontally scalable and latency-sensitive (target <50μs avg latency); Dreaming uses GPU-backed workers for LLM tasks.
- Use a durable queue (Redis Streams, Kafka, SQS) for backlog and claim/ack semantics with performance monitoring.
- Record prompt_hash, model_version, and msg_cid for every inference for reproducibility.
- cidstore integration: Deploy with WAL-enabled cidstore instances, configure auto-tuned batch sizes, implement exponential backoff retry logic for network failures, use ZMQ REQ/REP (port 5555) or PUSH/PULL (port 5557) for data operations, REST API (port 8000) for health checks and metrics.
- Performance monitoring: Track throughput (target >1M ops/sec), latency percentiles, batch size effectiveness, and error rates.

Pilot strategy
- Start with 1–2 high-value predicates (e.g., `t:joined`, `t:worksAt`) on a small user subset.
- Run symbolic extractor in production shadow mode for other predicates; route micro-LLM candidates to a staging validation loop.
```
### Zero-Cost Access
